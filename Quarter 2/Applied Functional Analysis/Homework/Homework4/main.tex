\input{definitions}

% Enter the specific assignment number and topic of that assignment below, and replace "Your Name" with your actual name.
\title{STAT 31210: Homework 4}
\author{Caleb Derrickson}
\date{February 2, 2024}

\begin{document}
\onehalfspacing
\maketitle
\allowdisplaybreaks
{\color{cit}\vspace{2mm}\noindent\textbf{Collaborators:}} The TA's of the class, as well as Kevin Hefner, and Alexander Cram.

\tableofcontents

\newpage
\section{Problem 5.2}
Suppose that $\{ e_1, e_2, ..., e_n\}$ and $\{\Bar{e}_1, \Bar{e}_2, ..., \Bar{e}_n\}$ are two bases of the n-dimensional linear space $X$, with
\[\Bar{e}_i = \sum_{j = 1}^nL_{ij}e_j, \quad e_i = \sum_{j = 1}^n \Bar{L}_{ij}\Bar{e}_j\]
where $L$ is an invertible matrix with inverse $\Bar{L}$, i.e., $\sum_{j = 1}^n L_{ij}\Bar{L}_{jk} = \delta_{ik}$. Let $\{\omega_1, \omega_2, ..., \omega_n\}$ and $\{ \Bar{\omega}_1, \Bar{\omega}_2, ..., \Bar{\omega}_n\}$ be the associated dual bases of $X\star$.
\subsection{Problem 5.2, part a}
If $x = \sum x_ie_i = \sum \Bar{x}_i \Bar{e}_i \in X$, then prove that the components of $x$ transform under a change of basis according to 
\[\Bar{x}_i = \Bar{L}_{ji}x_j, \quad \forall \ i = 1, ..., n\]
\partbreak
\begin{solution}

    If we start with the first expansion of $x$ in the basis $\{ e_1, e_2, ..., e_n\}$ and rewrite $e_i$ into the given form, we have 
    \[x = \sum_{i = 1}^n x_i e_i = \sum_{i = 1}^n x_i \sum_{j = 1}^n \Bar{L}_{ij}\Bar{e}_j.\]
    After some rearranging, we have
    \[x = \sum_{i = 1}^n \left(\sum_{j = 1}^n \Bar{L}_{ij}x_i \right)\Bar{e}_j.\]
    Note that the summation indices can be freely interchanged, so swapping the two indices, we have,
    \[x = \sum_{i = 1}^n \left(\sum_{j = 1}^n \Bar{L}_{ji}x_j \right)\Bar{e}_i.\]
    By the other expansion for $x$ in the basis $\{\Bar{e}_1, \Bar{e}_2, ..., \Bar{e}_n\}$, we can compare the coefficients in each expansion to get 
    \[\Bar{x}_i = \Bar{L}_{ji}x_j. \]
    Note that this holds for all $i = 1, ..., n$, which is what we wanted to show.
\end{solution}

\newpage
\subsection{Problem 5.2, part b}
If $\ph = \sum_{i = 1}^n \ph_i \omega_i = \sum_{i = 1}^n \Bar{\ph}_i \Bar{\omega}_i \in X\star$, then prove that the components of $\ph$ transform under a change of basis according to
\[\Bar{\ph}_i = \sum_{j  =1}^n L_{ij}\ph_j, \quad \forall \ i = 1, ..., n\]
\partbreak
\begin{solution}

    Investigating the action of $\ph$ onto the basis vector $\Bar{e_i}$, by the given mapping from $\Bar{e} \mapsto e$, we have 
    \[\ph(\Bar{e}_i) = \ph \left( \sum_{j = 1}^n L_{ij} e_j\right).\]
    Since $\ph$ is a linear operator, which only acts on coordinates, we have that 
    \[\ph(\Bar{e}_i) = \sum_{j = 1}^n L_{ij} \ph (e_j).\]
    By our notation, we write $\ph(\Bar{e}_i) = \Bar{\ph}$ and $\ph (e_j) = \ph_j$, thus we can write
    \[\Bar{\ph}_i = \sum_{j = 1}^n L_{ij} \ph_j.\]
    This formula will hold for any chosen $i \leq n$, since its choice was arbitrary. Thus, we have proven the statement. 
\end{solution}

\newpage
\section{Problem 5.6}
Let $X$ be a normed linear space. Use the Hahn-Banach Theorem to prove the following statements:
\begin{itemize}[a)]
    \item For any $x \in X$, there is a bounded linear functional $\ph \in X\star$ such that $\norm{\ph} = 1$ and $\ph (x) = \norm{x}$.
    \item[b)] If $x, y \in X$ and $\ph(x) = \ph(y) $ for any $\ph \in X\star$, then $x = y$.
\end{itemize}
\partbreak
\begin{solution}

    I will include the Hahn-Banach Theorem here for completeness.
    
    \begin{center}\rule{16.5cm}{0.5pt}\end{center}
    \begin{quote}
    \vspace{-6mm}
        \textbf{Hahn-Banach Theorem}: If $Y$ is a linear subspace of a normed linear space $X$ and $\psi: Y \rightarrow \R$ is a bounded linear functional on $Y$ with $\norm{\psi} = M$, then there is a bounded linear functional $\ph : X \rightarrow \R$ such that $\ph$ restricted to $Y$ is equal to $\psi$ and $\norm{\ph} = M$.  
    \end{quote}
    \vspace{-12mm}
    \begin{center}\rule{16.5cm}{0.5pt}\end{center}
    \begin{itemize}
    \item [a)] Let $x \in X$, and define the subspace $Y$ as any scaling of $x$. That is, $Y = \{ \lm x : \lm \in \R\}$. $Y$ is then a linear subspace of $X$, since it is closed under addition and scalar multiplication $(\mu y_1 + \gamma y_2 = \lm(\mu + \gamma)x \in Y)$. Define the functional $\psi: Y \rightarrow \R$ as $\psi (y \in Y) = \norm{y}_X = |\lm|\norm{x}_X$. We can note that $\psi$ is bounded, since 
    \[\norm{\psi} = \sup \frac{|\psi(y)|}{\norm{y}} = \sup\frac{|\lm \norm{x}}{\norm{\lm x}} = \sup \frac{|\lm|\norm{x}}{|\lm| \norm{x}} = 1.\]
    Therefore, $\norm{\psi} = 1$ for any $x \in X$. By the Hahn-Banach Theorem, there exists a bounded linear functional $\ph: X \rightarrow \R$ where $\ph|_{Y} = \psi$ and $\norm{\ph} = 1$. Therefore, $\norm{\ph} = 1$ and $\ph(x) = \norm{x}$ for any $x \in X$. 
    \item[b)] Suppose that $x \neq y \in X$, but $\ph (y) = \ph(x)$. Define $z = x - y \neq 0$. Note that $z \in X$, so by part a there is a linear functional $\ph'$ such that $\ph'(z) = \norm{z}$ and $\norm{\ph'} = 1$. The latter is notable, since we have that $\ph' \neq 0$. Thus, we have that 
    \[\ph'(z) = \norm{z} = \norm{x - y} \neq 0\]
    This then implies that $\ph'(x) \neq \ph'(y)$. Therefore, a linear functional has been found such that for $x \neq y, \ph(x) \neq \ph(y)$. Note that we suppose that $\ph(x) = \ph(y)$ should hold for all $\ph \in X\star$, thus $x = y$.
    \end{itemize}
\end{solution}

\newpage
\section{Problem 5.10}
Suppose that $k: [0, 1]\times [0, 1] \rightarrow \R$ is a continuous function. Prove that the integral operator $K : C([0, 1]) \rightarrow C([0, 1])$ defined by 
\[Kf(x) = \int_0^1 k(x, y) f(y) \ dy \quad \text{is compact.}\]
\partbreak
\begin{solution}

    By Definition 5.42, we need to show that for any bounded subset in $C([0, 1])$, $K(B)$ is a precompact subset of $C([0, 1])$. By Theorem 2.12 (Arzel\'a-Ascoli), we need to show that $\overline{K(B)}$ is bounded, closed, and equicontinuous in $C([0, 1])$. Define $A = [0, 1]$, which is a compact subset of $\R$.
    \begin{itemize}[-]
        \item \underline{Closed}: 

        \hop
        This is by definition of the closure of a set. Thus, $\overline{K(B)}$ is closed. 
        \item \underline{Bounded}: 

        \hop
        Take $f \in B \subseteq C([0, 1])$, then $\norm{f} = \sup_{x \in A} |f(x)|$. Thus we have
        \[\norm{Kf} = \norm{\int_0^1 k(x, y)f(y) \ dy} \leq \sup_{x \in A} \int_0^1 |k(x, y)f(y)| \ dy \leq \sup_{x \in A}\int_0^1 |k(x, y)||f(y)| \ dy\]
        Note that by definition, $|f(y)| \leq \sup_{y \in A} |f(y)| = \norm{f}$. This will add another inequality, as well as taking the norm outside of the integral (it is constant with respect to $y$). We then have that 
        \[\norm{Kf} \leq \norm{f}\sup_{x \in A}\left\{\int_0^1 |k(x, y)| \ dy\right\}.\]
        We are given in Example 5.17 that the sup on the right hand side is the norm of the integral operator. Thus we have that $\norm{Kf} \leq \norm{K}\norm{f}$, which implies that $\overline{K(B)}$ is bounded.
        \item \underline{Equicontinuity}:

        \hop
        Let $f_1, f_2 \in B$. To show equicontinuity, we need to find a $\delta$ such that, for any $\ep > 0$, when $d(f_1, f_2 < \delta$, we have that $d(Kf_1, Kf_2) < \ep$. Note the metric we are working under is the sup-norm, so $d(f_1, f_2) = \sup_{x \in A} |f_1(x) - f_2(x)|$, and similar for $d(Kf_1, Kf_2)$. Set $\delta = \frac{\ep}{\norm{K}}$. Then, we see the following:
        \newpage
        \tightalignbreak
        \begin{align*}
            &\norm{Kf_1 - Kf_2} =\sup_{x \in A}\left|Kf_1(x) - Kf_2(x)\right| &\text{(Given.)}\\
            &= \sup_{x \in A}\left|K(f_1(x) - f_2(x))\right| &\text{(Grouping.)}\\
            &\leq \sup_{x \in A}\left\{ \norm{K}|(f_1(x) - f_2(x))|\right\} &\text{(Cauchy-Schwartz.)}\\
            &= \norm{K} \sup_{x \in A}\left\{ |f_1(x) - f_2(x)|\right\} &\text{(Rearranging.)}\\
            &< \norm{K}\left( \frac{\ep}{\norm{K}}\right) &\left(\delta = \frac{\ep}{\norm{K}}.\right)\\
            &= \ep &\text{(Simplifying.)}
        \end{align*}
        \vspace{-12mm}\alignbreak
        Therefore, $K$ is an equicontinuous linear mapping. Thus by Arzel\'a - Ascoli, $\overline{K(B)}$ is a compact subset of $C([0, 1])$, which means that $K$ is a compact operator. 
        
    \end{itemize}
\end{solution}
\newpage
\section{Problem 5.11}
Prove that if $T_n \rightarrow T$ uniformly, then $\norm{T_n} \rightarrow \norm{T}$.
\partbreak
\begin{solution}

    We have that $T_n \rightarrow T$ uniformly, that is, $\lim_{n \rightarrow 0} \norm{T_n - T} = 0$. Let $\ep > 0$. Since $T_n \rightarrow T$, there exists some $N \in \N$ such that when $n \geq N \implies \norm{T_n - T} < \ep$. A quick shortcut can be made via the reverse triangle inequality, but I will explain it slightly more. Consider $\norm{T_n}$. This is equivalent to $\norm{T_n - T + T}$, that is, adding and subtracting the same number such that we maintain equality. By the triangle inequality, we have that 
    \[\norm{T_n - T + T} \leq \norm{T_n - T} + \norm{T}.\]
    Therefore, we have that $\norm{T_n} - \norm{T} \leq \norm{T_n - T}$. By symmetry of the argument, we have that 
    \[\big|\norm{T_n} - \norm{T}\big| \leq \norm{T_n - T}.\]
    Since $\norm{T_n - T} < \ep$ for sufficiently large $n$, then by the reverse triangle inequality explained above, we have that 
    \[\big| \norm{T_n} - \norm{T} \big| < \ep, \quad \text{For sufficiently large $n$.}\]
    Therefore, $\lim_{n\rightarrow\infty} \big|\norm{T_n} - \norm{T}\big| = 0$, or equivalently, $\norm{T_n} \rightarrow \norm{T}$.
\end{solution}
\newpage
\section{Problem 5.17}
Suppose that $K : X \rightarrow X$ is a bounded linear operator on a Banach space $X$ with $\norm{K} < 1$. Prove that $\id - K$ is invertible and 
\[(\id - K)\inv  = \id + K + K^2 + K^3 + ...,\]
where the series on the right hand side converges uniformly in $\mathfrak{B}(X)$.
\partbreak
\begin{solution}

    We will first show that $\id - K$ is invertible. Note that this is equivalent to showing $\norm{\id - K} > 0$, since if it were, then $\id  - K$ would have a nonzero kernel. By the reverse triangle inequality, we can write
    \[\big| \norm{\id} - \norm{K} \big| \leq \norm{\id - K}\]
    We have that $\norm{K} < 1$, and $\norm{\id} = 1$. Therefore, $\norm{ \id} - \norm{K} > 0$, implying that $\norm{\id - K} > 0$, thus $\id - K$ is invertible. Next, we need to show that its inverse is of the given form. Define $A_n$ as the $n$-th iterate of the sequence on the right hand side, so we can write
    \[A_n = \sum_{j = 0}^n K^j\]
    Multiplying on the left by $(\id - K)$ gives
    \[(\id - K) A_n = (\id - K)\sum_{j = 0}^n K^j = \sum_{j = 0}^n K^j - K^{j+1}\]
    We note that $(\id - K)$ is a telescoping series, so we will only be left with $K^0$ and $-K^{n+1}$, giving
    \[(\id - K) A_n = \id - K^{n+1}\]
    Next we need to show that $K^{n+1} \rightarrow 0$ as $n \rightarrow \infty$ in order to justify the equality. Note that $\norm{K} < 1$, so $\norm{K}^2 \leq \norm{K}$. Thus for some index $m$, we note that $\norm{K}^m \leq \norm{K}^{m-1} < ... < 1$, thus the sequence $\norm{K}^m$ is a monotonically decreasing sequence in $\R$. By the properties of the norm, this sequence is bounded below by zero, and is bounded above by the previous iterate of the sequence. Thus, there is a converging subsequence $\norm{K}^{\ph(n)} \rightarrow 0$ as $\ph(n) \rightarrow \infty$, which implies $\norm{K}^n \rightarrow 0$, so $K^n \rightarrow 0$ as $n\rightarrow \infty$. This implies that $\lim_{n \rightarrow \infty}A_n = (\id - K)\inv$. We can recover the bound of the norm on the right hand side by the following:
    \newpage
    \tightalignbreak
    \begin{align*}
        &\norm{\lim_{n \rightarrow \infty} A_n} &\text{(Given.)}\\
        &= \lim_{n \rightarrow \infty}\norm{A_n} &\text{(Limits exist.)}\\
        &=\lim_{n \rightarrow \infty}\norm{\sum_{j = 0}^n K^j} &\text{(Definition.)}\\
        &\leq \lim_{n \rightarrow \infty}\sum_{j = 0}^n \norm{K^j} &\text{(Triangle inequality.)}\\
        &\leq \lim_{n \rightarrow \infty}\sum_{j = 0}^n \norm{K}^j &\text{(Cauchy-Schwartz.)}\\
        &= \frac{1}{1 - \norm{K}} &\text{(Geometric series.)}
    \end{align*}
    \vspace{-12mm}\alignbreak
    Therefore, the norm on the right hand side is bounded by $(1 - \norm{K})\inv$. This is well defined, since $\norm{K} < 1$. Therefore, $\lim_{n \rightarrow \infty} A_n \in \mathfrak{B}(X)$, which completes the proof.
\end{solution}
\end{document}