{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e784334a",
   "metadata": {},
   "source": [
    "# Spectral Clustering and Image Segmentation\n",
    "\n",
    "We talked in class about spectral clustering and how it works. In this notebook you will implement it and then apply it to images as described in [Shi & Malik](https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Hashable\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = np.array(['tab:blue', 'orange'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2582ce1",
   "metadata": {},
   "source": [
    "## Sweep Cuts\n",
    "\n",
    "The first component you will need is a function computing the best sweep cut. The returned cut $S$ is computed as the $S_t = \\{i : v[i] \\leq t\\}$. Take care to compute the conductance \n",
    "$$\\phi(S) = \\frac{w(E(S, \\bar{S})}{\\min\\left\\{\\text{vol}(S), \\text{vol}(\\bar{S})\\right\\}}$$\n",
    "of all threshold cuts in $O(|V| + |E|)$ using running sums.\n",
    "\n",
    "To begin with, you will use your function on the path graph, before applying them to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_cut(G: nx.Graph, x: np.ndarray) -> (float, float, np.ndarray):\n",
    "    \"\"\"Sweep Cut\n",
    "    \n",
    "    Also known as threshold cut, takes in a graph and a\n",
    "    1D embedding of the nodes and returns a threshold,\n",
    "    the conductance from the associated threshold cut and\n",
    "    a 0/1 vector indicating which side of the cut each node\n",
    "    belongs to in the best conductance cut.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        The graph to compute the threshold cut for.\n",
    "    x : np.ndarray\n",
    "        1D Embedding of the nodes in G.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    thr : float\n",
    "        The best conductance threshold.\n",
    "    conductance : float\n",
    "        Conductance \\phi(S) = w(E(S, \\bar{S})) / min(vol(S), vol(\\bar{S}))\n",
    "        of the best threshold cut\n",
    "    cut : np.ndarray\n",
    "        0/1 indicator vector of the best threshold cut.\n",
    "        It holds that cut = (x <= thr)\n",
    "    \"\"\"\n",
    "    n = len(G)\n",
    "    # TODO: Compute the threshold for best conductance cut\n",
    "    #\n",
    "    #       \\phi(S) = w(E(S, \\bar{S})) / min(vol(S), vol(\\bar{S}))\n",
    "    #\n",
    "    #       Your code should take advantage of the fact that\n",
    "    #       the difference between two adjacent threshold cuts\n",
    "    #       is a single node. Total running time should be O(|V| + |E|).\n",
    "    if len(x.shape) != 1:\n",
    "        raise ValueError(f'Embedding should be one dimensional. Instead got `x` with shape {x.shape}.')\n",
    "    \n",
    "    thr = x.min()\n",
    "    conductance = np.inf\n",
    "    cut = np.zeros(n, int)\n",
    "    \n",
    "    return thr, conductance, cut\n",
    "\n",
    "\n",
    "n = 100\n",
    "P = nx.path_graph(n)\n",
    "nx.set_edge_attributes(P, 1, 'weight')\n",
    "x = np.linspace(0, 1, n)\n",
    "thr, cond, cut = sweep_cut(P, x)\n",
    "\n",
    "print(f'On the path with {n} nodes the best conductance threshold is thr = {thr:.6f} and yields conductance {cond:.6f}.')\n",
    "pos = nx.spectral_layout(P)\n",
    "nx.draw(P, pos=pos, node_color=colors[cut], node_size=50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b00a0d8",
   "metadata": {},
   "source": [
    "## Spectral clustering\n",
    "\n",
    "Now that you have the sweep cut implemented, you can implement spectral clustering by simply finding the $k$-th eigenvalue and determining the best cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85766cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "def spectral_clustering(G: nx.Graph, k: int=2) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"Spectral Clustering\n",
    "    \n",
    "    Taking a graph `G` and an integer `k`,\n",
    "    Compute the k-th eigenvector.\n",
    "    Decide on the best threshold cut.\n",
    "    Return a vector of its nodes with values\n",
    "    in {0, 1} indicating which side of the cut each node belongs to.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        Graph to do spectral clustering on.\n",
    "    k : int\n",
    "        Which eigenvectors to use for clustering.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    v : np.ndarray\n",
    "        The first k+1 eigenvectors.\n",
    "    cut : np.ndarray\n",
    "        0/1 indicator vectors of the best threshold cut on the {1, ..., k+1} eigenvectors. \n",
    "    \"\"\"\n",
    "    n = len(G)\n",
    "    if not (1 <= k <= n):\n",
    "        raise ValueError(f'The choice of `k` must be between 1 and n. Instead {k} was passed.')\n",
    "    \n",
    "    # TODO: Compute the (k+1)-th smalest eigenvectors \\lambda_k(L, D) of graph G\n",
    "    #       and return the best sweep cuts for each one as 0/1 vector\n",
    "    #       Make sure that the degree matrix is computed correctly for weighted vectors.\n",
    "    #       Hint: Use scipy.sparse.linalg.eigsh\n",
    "    v = np.zeros((n, k+1))\n",
    "    cut = [np.zeros(n, int) for _ in range(k)]\n",
    "    \n",
    "    return v, cut\n",
    "\n",
    "_, cut = spectral_clustering(P, 1)\n",
    "nx.draw(P, pos=pos, node_color=colors[cut[0]], node_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be100b57",
   "metadata": {},
   "source": [
    "### Spectral Clustering on Manifolds\n",
    "\n",
    "First we will work on artificial datasets sampled from manifolds. The machine learning library `sklearn` has some generators for commonly used manifolds that are difficult to learn.\n",
    "\n",
    "A common way to recover a graph from a manifold is through $k$-nearest neighbors. Each node connects to their $k$ closest neighbors. There are variations on this technique, such as weighing the edges based on their rank or distance. You need to implement a basic undirected version, where the weight is 1 if $v$ is in the $k$NN of $u$ and 2 if $u$ is also in the $k$NN of $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17611319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "\n",
    "def generate_datasets(k=5, noise_multiplier=1):\n",
    "    # ============\n",
    "    # Generate datasets. We choose the size big enough to see the scalability\n",
    "    # of the algorithms, but not too big to avoid too long running times\n",
    "    # ============\n",
    "\n",
    "    n_samples = 500\n",
    "    seed = 17\n",
    "    noisy_circles = datasets.make_circles(\n",
    "        n_samples=n_samples, factor=0.5, noise=0.07 * noise_multiplier, random_state=seed\n",
    "    )\n",
    "    noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.10 * noise_multiplier, random_state=seed)\n",
    "    data = []\n",
    "\n",
    "    for i, (X, y) in enumerate([noisy_circles, noisy_moons]):\n",
    "        G = nx.empty_graph(n_samples)\n",
    "        # TODO: Use `kneighbors_graph` with n_neighbors equal to 5 to construct a graph\n",
    "        #       a graph from each dataset.\n",
    "        #       One way to make it into an undirected graph is to take A_u = (A_d + A_d^T) / 2\n",
    "        #       This will give you the adjacency matrix.\n",
    "        #       You can make it into a graph using `nx.from_scipy_sparse_matrix\n",
    "\n",
    "        data.append([X, y, G])\n",
    "\n",
    "    return data\n",
    "\n",
    "data = generate_datasets()\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "for i, (X, y, G) in enumerate(data):\n",
    "    ax[0][i].scatter(X[:, 0], X[:, 1], s=10, color=colors[y])\n",
    "    plt.sca(ax[1][i])\n",
    "    nx.draw(G, pos=X, node_color=colors[y], node_size=5)\n",
    "    \n",
    "    for j in range(2):\n",
    "        ax[j][i].set_aspect('equal', 'box')\n",
    "        ax[j][i].set_xticks([])\n",
    "        ax[j][i].set_yticks([])\n",
    "        for side in ['right', 'top', 'left', 'bottom']:\n",
    "            ax[j][i].spines[side].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc6bc8",
   "metadata": {},
   "source": [
    "Find the best conductance sweep cut from $\\mathbf{v}_2$ and plot the result similarly as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cfe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "def accuracy_recall_f1(y: np.ndarray, cut: np.ndarray) -> Tuple[float, float, float]:\n",
    "    cov = cut @ y\n",
    "    cov2 = (1 - cut) @ (1 - y)\n",
    "    accuracy = 2 * (max(cov, len(G) / 2 - cov)) / len(G)\n",
    "    recall = 2 * (max(cov2, len(G) / 2 - cov2)) / len(G)\n",
    "    f1 = (2 * recall * accuracy) / (recall + accuracy)\n",
    "    return accuracy, recall, f1\n",
    "\n",
    "\n",
    "for i, (X, y, G) in enumerate(data):\n",
    "    # TODO: Use your spectral_clustering function to try and recover the original clusters. \n",
    "    n = len(G)\n",
    "    v = np.zeros((n, 2))\n",
    "    cut = [np.zeros(n, int)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    accuracy, recall, f1 = accuracy_recall_f1(y, cut[0])\n",
    "    print(f'Accuracy is {accuracy:.3f}. Recall = {recall:.3f}. F1-score = {f1:.3f}.')\n",
    "    plt.sca(ax[i])\n",
    "    nx.draw(G, pos=X, node_color=colors[cut], node_size=5)\n",
    "    ax[i].set_aspect('equal', 'box')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    for side in ['right', 'top', 'left', 'bottom']:\n",
    "        ax[i].spines[side].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd88cc7",
   "metadata": {},
   "source": [
    "# Choice of $k$\n",
    "\n",
    "Different choices of $k$ lead to different behaviors. Vary the value for `k` the number of neighbors and observe how the `F1-score` changes.\n",
    "Comment on what drives this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a0ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_neighbors = [2, 3, 4, 5, 6, 7, 8, 10, 15, 20, 30, 40,  50]\n",
    "f1 = np.zeros([len(possible_neighbors), 2])\n",
    "for j, k in enumerate(possible_neighbors):\n",
    "    # TODO: Generate new datasets with different number of nearest neighbors\n",
    "    #       and compute the best conductance cut based on the second eigenvector\n",
    "    ...\n",
    "        \n",
    "plt.plot(possible_neighbors, f1[:, 0], label='Circles')\n",
    "plt.plot(possible_neighbors, f1[:, 1], label='Moons')\n",
    "plt.axis(ymin=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c342185",
   "metadata": {},
   "source": [
    "### Spectral Clustering for Image Segmentation\n",
    "\n",
    "So far you have implemented sweep cut and spectral clustering. Now you will load some images from the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/), construct a graph based on the distance and color difference of the pixels and segment the image using spectral clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ee666",
   "metadata": {},
   "source": [
    "Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "def block_mean(ar, fact):\n",
    "    assert isinstance(fact, int), type(fact)\n",
    "    sx, sy = ar.shape\n",
    "    X, Y = np.ogrid[0:sx, 0:sy]\n",
    "    regions = sy//fact * (X//fact) + Y//fact\n",
    "    res = ndimage.mean(ar, labels=regions, index=np.arange(regions.max() + 1))\n",
    "    res = res[:((sx // fact) * (sy // fact))]\n",
    "    res.shape = (sx//fact, sy//fact)\n",
    "    return res\n",
    "\n",
    "image_filenames = [f for f in os.listdir('images') if f.endswith('jpg')]\n",
    "image_names = [os.path.splitext(f)[0] for f in image_filenames]\n",
    "mask_filenames = [f'{f}.png' for f in image_names]\n",
    "\n",
    "images = [imageio.imread(os.path.join('images', filename)) / 255 for filename in image_filenames]\n",
    "masks = [imageio.imread(os.path.join('images', filename)) for filename in mask_filenames]\n",
    "\n",
    "factor = 5\n",
    "subsampled_images = []\n",
    "for i, im in enumerate(images):\n",
    "    sx, sy, _ = im.shape\n",
    "    subsampled_im = np.zeros((sx // factor, sy // factor, 3))\n",
    "    for c  in range(3):\n",
    "        subsampled_im[:, :, c] = block_mean(im[:, :, c], factor)\n",
    "    subsampled_images.append(subsampled_im)\n",
    "    \n",
    "for im, m in zip(subsampled_images, masks):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(im)\n",
    "    ax[1].imshow(m)\n",
    "    \n",
    "    for a in ax:\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e3164",
   "metadata": {},
   "source": [
    "Shi and Malik define a graph by iterating over pixels.\n",
    "The edge weight between two pixels depends on their physical distance and the norm of the difference between the pixel colors.\n",
    "\n",
    "$$w_{ij} = e^{\\frac{-\\|F(i) - F(j)\\|_2^2}{0.03}} \\times \\begin{cases} e^{\\frac{-\\|X(i) - X(j)\\|_2^2}{10}} & \\text{if} \\|X(i) - X(j)\\|_2 < 5 \\\\ 0 & \\text{otherwise} \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def generate_graph_from_image(image: np.ndarray, dist=5, sigma_i=0.03, sigma_X=10) -> nx.Graph:\n",
    "    rows, cols, _ = image.shape\n",
    "    def coord_to_node(i, j):\n",
    "        return i * cols + j\n",
    "    start = datetime.now()\n",
    "    edges = []\n",
    "    for i in range(rows):\n",
    "        print(f'\\rProcessed {i + 1:3d} rows in {(datetime.now() - start).total_seconds():7.3f}', end='')\n",
    "        # TODO: Create an undirected weighted graph from the given image\n",
    "        #       Each graph should take 10-20s to generate.\n",
    "        ...\n",
    "        \n",
    "        \n",
    "    G = nx.Graph()\n",
    "    G.add_weighted_edges_from(edges)\n",
    "    return G\n",
    "\n",
    "\n",
    "rows, cols, _ = subsampled_images[1].shape\n",
    "start = datetime.now()\n",
    "graphs = []\n",
    "for im in subsampled_images:\n",
    "    G = generate_graph_from_image(im, dist=5, sigma_i=0.03, sigma_X=10)\n",
    "    print(f'\\rGenerated graph with {len(G)} nodes and {len(G.edges)} edges in {(datetime.now() - start).total_seconds():6.2f} seconds.')\n",
    "    graphs.append(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18445ee",
   "metadata": {},
   "source": [
    "It is time to see the result of your work on these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "k = 5\n",
    "cuts = []\n",
    "eigenvectors = []\n",
    "for j, G in enumerate(graphs):\n",
    "    print(f'Performing spectral clustering for {image_names[j]}')\n",
    "    v, cut = spectral_clustering(G, k=k)\n",
    "    cut = [c.reshape(subsampled_images[j].shape[:2]) for c in cut]\n",
    "    eigenvectors.append(v)\n",
    "    cuts.append(cut)\n",
    "    print(f'Done after {(datetime.now() - start).total_seconds():.2f} seconds...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1c975",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "We can visualize the eigenvector, the mask from the sweep cut and how the image looks masked with each cut.\n",
    "What do you notice in each image? What drives cuts in each image?\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d425d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j, cut in enumerate(cuts):\n",
    "    print(f'Spectral clustering for {image_names[j]}')\n",
    "    masked_images = []\n",
    "    fig, ax = plt.subplots(3, k, figsize=(15, 8))\n",
    "    for i in range(k):\n",
    "        ax[0][i].imshow(eigenvectors[j][:, i + 1].reshape(subsampled_images[j].shape[:2]), cmap='Greys')\n",
    "        ax[1][i].imshow(cut[i], cmap='Greys')\n",
    "\n",
    "        ind_x, ind_y = np.where(cut[i])\n",
    "        im_hsv = mpl.colors.rgb_to_hsv(subsampled_images[j])\n",
    "        im_hsv[ind_x, ind_y, 2] /= 3\n",
    "        masked_images.append(mpl.colors.hsv_to_rgb(im_hsv))\n",
    "        ax[2][i].imshow(masked_images[i])\n",
    "\n",
    "    for a in ax.reshape(-1):\n",
    "        a.set_xticks([])\n",
    "        a.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc549e30",
   "metadata": {},
   "source": [
    "# Optional extensions\n",
    "\n",
    "If you want, you can further experiment with these techniques to expand your udnerstanding.\n",
    "\n",
    "- How does the distance affect the running time and quality of your cuts?\n",
    "- What are the effects on the image when changing the $\\sigma_I$ and $\\sigma_X$ quantities of the graph generation?\n",
    "- You worked on downsized images. How does the same technique perform on the original images? Why?\n",
    "- This technique gives one cut each time. How would you extend it to $k$ cuts?\n",
    "- Future papers normalized the eigenvectors before finding cuts. You can read more on [Ng, Jordan, Weiss](https://papers.nips.cc/paper_files/paper/2001/file/801272ee79cfde7fa5960571fee36b9b-Paper.pdf). After the work you have done, implementing that paper is not insurmountable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
